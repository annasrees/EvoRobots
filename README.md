# Advanced Evolutionary Robotics
Repository for Evolutionary Robotics, University of Vermont, CS5060

## Contents
This repository contains all 10 main assignments throughout the course, split by name into branches. Additionally, the final project is contained in a branch as well

## Final Project
For my final project, I decided to create a "Love bot", a robot built on an evolutionary algorithm which can learn to seek out an object in its world and hug it, or wrap its arms around the object.

# Goals 

The overall goal for this project was to create a “Lovebot”, a robot that can evolve to hug an object. To do so, I created a biped robot and a target block. Within the deliverables, several smaller projects arose for this goal to be executed. Firstly, for the robot to successfully hug the block target, the robot would have to be able to stay upright and pitch its body weight towards the block. So, the first goal for this robot was to evolve stability to remain upright. Once the ability to remain upright and pitch toward the block was established, the second major goal established during the deliverables was to be able to wrap the robot’s arms around the block. This process meant adjusting the body of the robot, so the arms had the proper degrees of freedom to push forward and away from the body. From here, the “A” variant was the same design that had been used for the first three milestones, but with a very slight tweak to the fitness function so as not to give this model an unfair advantage over the “B” model. The “B” variant was the same robot as the “A” variant, but with the target block moved away three units from the bot. In doing so, I sought to find out if while evolving for a “hugging” ability, the robot could also evolve bipedal locomotion and be able to seek out a target away from themselves. 

# Implementation Details 

Throughout the project, the robot's body was coded and adjusted in tandem with the robot's fitness function as necessary. To create the biped, 14 links were used to create the head, torso, arms, shoulders, legs, and feet. During the third milestone, the “mass patch” was added so that the feet of the robot could have more mass and therefore provide more stability to the bot, and the block could also have higher mass and would be harder to knock over. The shoulder attached to the torso, and the upper arm attached to the shoulder, were given a z joint axis, so the arms were able to move out and away from the body to wrap around the block. The leg joints were all given a y joint axis, so the robot was able to, in concept, swing its leg links and feet as a pendulum, which would make locomotion possible. 

To make an A and B variant of the project, I had to modify several files to be able to take in the information of whether the run was an A variant or B variant and to store, process, and analyze the subsequent data from these runs. First, in search.py, I modified the code to have two instances of parallelHillClimber, one for A, and one for B. To differentiate the two, I passed a character variable corresponding to the run (“A” or “B”) into parallelHillClimber.py’s constructor. This character variable was then passed into each instantiation of solution from the self.parents dictionary. In solution,py, I then had to create two functions: one which created the A variant block with position [1, 0, 1.5], and one to which created the B variant block with position [3, 0, 1.5]. Depending on what kind of run we are performing, either the A block or the B block was built.  

The robot’s fitness was determined by the robot’s relative arm position, or the difference between the arm joints and the bot’s torso, and its relative x position, or the difference between the bot’s position and the block’s position in the x-axis. In other words, the robot’s fitness was determined by how well it was able to maximize the distance between its body and arms and minimize the distance between itself and the block. To store and handle the finesses, a fitness matrix function was written into solution.py, which sent the fitnesses identified by each run to a file, which was then read and processed by a new plotFitnessFunctions.py file. Since the B variant was initialized to be farther away from the block, it was at a natural disadvantage to the A variant. To account for this, I adjusted the B variant’s fitness matrix to accommodate for the initial distance. This way, fitness is determined more by the robot’s effort to seek out a hug from the block, so to speak, than its actual success in doing so.  

# Results 

To compare the fitness of the A and B variants, I ran the A variant and B variant 10 times, then plotted the fitness over each generation. For each run, a population of size 10 was created with random initial synaptic weights and ran for 10 generations. The best fitness out of the populations was identified for each generation. These can be provided upon request.

Based on the mean fitness plots for the 10 generations of A and B variants, it is easy to see that both variants evolve improved fitness over generations. The mean plot of the B variant is slightly below the mean plot for A for most generations, but after the 6th generation the mean fitness lines intersect, and B has a higher mean fitness at generation 10. Based on this plot, the two variants evolved functionally the same quality of robot. 

# Discussion 

Overall, this project was a challenging yet rewarding undertaking. I was surprised by the intricacies required to add or modify program features. For example, implementing the “mass patch” was quite difficult for me, because there are so many files and functions working together which must be modified in just the right way. I was also surprised by how difficult it was to make the robot move in the way I wanted it to. Identifying the correct degree(s) of freedom for each joint and implementing this correctly so it can move how it needs to be another unanticipated challenge for me in this project. I was surprised how easy it was to create the biped, and the fitness function also felt intuitive to create in an effective way. With another year’s worth of work, I think the B variant would be interesting to expand further by evolving a robot to seek out another object and to grab onto it with its arms. I can imagine this would have extensive applications in the real world and could be done in a myriad of ways. Perhaps, this robot could have new features from Pyrosim, such as visual sensors so it could “see” where the block is relative to itself. I think adding this new type of sensory input could be challenging to evolve in the expanded project idea, but I think it is conceptually quite compelling. 
